{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d610d5a2-674d-4b26-b980-111285a27697",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Collaboration with Yuri @Ziv's lab\n",
    "Dyskinesia progerssion GWAS\n",
    "\n",
    "\n",
    "#### predictors\n",
    "GWAS and some targeted SNPs + GBA, LRRK2 score analyses\n",
    "\n",
    "\n",
    "\n",
    "#### Strata\n",
    "All sample analysis, male only analysis, female only analysis\n",
    "\n",
    "\n",
    "#### Models\n",
    "no adjustment - only PC1-3. adjustment - plus those in [ ] \n",
    "\n",
    "Linear: Disease_duration(the duration to the first Dyskinesia==1)~SNP+PC1+PC2+PC3 [+PD_AAO+Sex+HY(ExceptForCORIELL):for ADJ]\n",
    "\n",
    "Lotistic: Dyskinesia~SNP+PC1+PC2+PC3 [+Disease_duration+PD_AAO+Sex+HY(ExceptForCORIELL):for ADJ]\n",
    "\n",
    "Survival: Dyskinesia~SNP+PC1+PC2+PC3 [+PD_AAO+Sex+HY(ExceptForCORIELL):for ADJ] + Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c65593-f322-4a1e-9603-a29cfcef538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "from IPython.core.debugger import set_trace # insert 'set_truce()' inside function for debagging\n",
    "import matplotlib as plt\n",
    "\n",
    "# Some job control commands\n",
    "def submitMultiJobs(x, time='3:00:00', mem=2, bundle=1, modules=None, store='swarm', node='quick', packing=True, go=False):\n",
    "    \"\"\"\n",
    "    Submit multiple jobs on biowulf\n",
    "    x: LIST of the location of swarmfile\n",
    "    max runtime: quick->4:00:00, norm->48:00:00 be careful when bundle jobs\n",
    "    node: quick or norm\n",
    "    example of modules: modeule='R,plink'\n",
    "    'go=True' will submit the jobs\n",
    "    \"\"\"\n",
    "    swarmdevq=\"swarm -f {F} --time={T} -g {G} -p {PACK} -b {B} --logdir {L}{M} --partition={P} --devel\"\n",
    "    a=[]\n",
    "    MODULES=' --module {M}'.format(M=modules)*(modules is not None)\n",
    "    for i in x: \n",
    "        s=swarmdevq.format(F=i, T=time, G=mem, PACK=1+packing, B=bundle, M=MODULES, L=store, P=node)\n",
    "        if go:\n",
    "            res=subprocess.run(s[:-8].split(\" \"), stdout=subprocess.PIPE)\n",
    "            a.append(res.stdout.decode('utf-8'))\n",
    "        if not go:\n",
    "            res=subprocess.run(s.split(\" \"), stdout=subprocess.PIPE)\n",
    "            t = res.stdout.decode('utf-8').replace(',', '--').replace('\\n', '--').replace(' /spi', '--').split(\"--\")\n",
    "            x = [i for i,x in enumerate(t) if 'cpus-' in x]\n",
    "            print(t[1:3]+t[x[0]:-2])\n",
    "            a='Check!![module, N_jobs, node, mem(x2), and store,bundle] If ok -> go=True!'\n",
    "    return(a)\n",
    "\n",
    "\n",
    "def checkJobStatus(list_of_jobids):\n",
    "    \"\"\"\n",
    "    Get the job status as the list of dataframe with some outputs\n",
    "    \"\"\"\n",
    "    ans = []\n",
    "    index=0\n",
    "    for i in list_of_jobids:\n",
    "        res = subprocess.run(['jobhist', str(i)], stdout=subprocess.PIPE)\n",
    "        res2 = res.stdout.decode().split('\\n')\n",
    "        start = next(i for i,x in enumerate(res2) if 'Jobid' in x)\n",
    "        start_script = next(i for i,x in enumerate(res2) if '/usr/local/bin/swarm -f' in x)\n",
    "        script = res2[start_script].replace('Swarm Command      : /usr/local/bin/swarm -f ', '').split('--')[0]\n",
    "        s = pd.Series(res2[start:])\n",
    "        df = s.str.split(\"\\\\s{2,}\", expand=True)\n",
    "        df = df.rename(columns=df.iloc[0, :])\n",
    "        a=df[1:-2]\n",
    "        print('=========== index=' + str(index) + \": jobID=\" + i + \": \" + script + ' ===============')\n",
    "        print(\"N of Jobs: \" + str(a.shape[0]))\n",
    "        print('N_of not_COMPLETED: '+str(sum(a.State!='COMPLETED')))\n",
    "        print(\"First 5 of longest Runtime job\")\n",
    "        print(a.sort_values('Runtime', ascending=False).head())\n",
    "        print(\"Pending jobs\"+str(list(a[a.State=='PENDING'].Jobid)))\n",
    "        ans.append(a)\n",
    "        index += 1\n",
    "    return (ans)\n",
    "\n",
    "def plotRuntime(Runtime):\n",
    "    \"\"\"\n",
    "    Create plot from Outputted Runtime from checkJobStatus\n",
    "    \"\"\"\n",
    "    def convertH(runtime):\n",
    "        h, m, s = runtime.split(':')\n",
    "        return int(h) + int(m) / 60 + int(s)/3600\n",
    "    Runtime.apply(convertH).plot.hist()\n",
    "\n",
    "def checkSubjob(subjobID):\n",
    "    \"\"\"\n",
    "    Get the command of subjobs to check. \n",
    "    Provide subjobID in string\n",
    "    \"\"\"\n",
    "    header='/spin1/swarm/iwakih2/'\n",
    "    findfolder=header+subjobID.replace(\"_\", '/cmd.')\n",
    "    files = glob.glob(findfolder+'_*')\n",
    "    for file in files:\n",
    "        res = subprocess.run(['cat', file], stdout=subprocess.PIPE)\n",
    "        return(print(res.stdout.decode()))\n",
    "\n",
    "def retrieveTimeouts(x, output):\n",
    "    \"\"\"\n",
    "    Writing timeouted jobs in 'output'\n",
    "    x is the output dataframe from \"checkJobStatus\"\n",
    "    \"\"\"\n",
    "    failed=x[x.State=='TIMEOUT'].Jobid\n",
    "    header='/spin1/swarm/iwakih2/'\n",
    "    findlist=[header+i.replace(\"_\", '/cmd.') for i in failed]\n",
    "    with open(output, 'w') as f:\n",
    "        for i in findlist:\n",
    "            files = glob.glob(i+'_*')\n",
    "            for file in files:\n",
    "                res = subprocess.run(['cat', file], stdout=subprocess.PIPE)\n",
    "                f.write(res.stdout.decode()[3:-2] + '\\n')\n",
    "def cutSwarmByNjobs(swarmfile, N=2000):    \n",
    "    a = []\n",
    "    with open(swarmfile) as f:\n",
    "        lines = f.read().splitlines()\n",
    "        N_split = len(lines)//N\n",
    "        for i in range(N_split+1):\n",
    "            fname,ext = swarmfile.split('.')\n",
    "            newfile='{0}_{1}cut{2}.{3}'.format(fname, str(N), str(i), ext)\n",
    "            a.append(newfile)\n",
    "            with open(newfile, 'w') as f:\n",
    "                f.write('\\n'.join(lines[(i*N):((i+1)*N)]))\n",
    "    return (a)\n",
    "\n",
    "def submitTerminal(command, printing=False, message=''):\n",
    "    # quick command to submit jobs to terminal\n",
    "    start = time.time()\n",
    "    res=subprocess.run(command.split(' '), stdout=subprocess.PIPE)\n",
    "    end = time.time()\n",
    "    sys.stdout.write('EXEC_TIME in sec: '+ str(round(end - start, 3)) + ' : ')\n",
    "    if printing:\n",
    "        print(res.stdout.decode('utf-8'))\n",
    "    if message=='':\n",
    "        return(res.stdout.decode('utf-8'))\n",
    "    else:\n",
    "        print(message, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971b31cf-5165-43ea-bfd2-2663dbb8a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET=[\"CORIELL\", \"PRECEPT\", \"SCOPA\"]\n",
    "OUTPUT=\"cohort/\"\n",
    "CHRNUM=['chr'+str(i) for i in range(1,23)]\n",
    "IMPUTED='/data/LNG/CORNELIS_TEMP/progression_GWAS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa77ca2a-8972-410c-8b46-02e890f5f23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORIELL 153\n",
      "PRECEPT 149\n",
      "SCOPA 399\n"
     ]
    }
   ],
   "source": [
    "# Cuts per 20K based on maf 0.01 and rsq 0.3 were previously conducted. chack the number of cutted files.\n",
    "for i in DATASET:\n",
    "    check= \"ls /data/LNG/iwakih2/dataset/{dataset}/maf01rsq3_20Kcut/\"\n",
    "    bash =check.format(dataset=i)\n",
    "    res=subprocess.run(bash.split(\" \"), stdout=subprocess.PIPE)\n",
    "    num=res.stdout.decode('utf-8').count('gz')\n",
    "    print(i, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e5195f-fed0-44eb-8043-de3e5523f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two different arrays\n",
    "NEUROX=['CORIELL', 'PRECEPT']\n",
    "CHIP=list(set(DATASET)-set(NEUROX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f4769d-4306-4bb1-9efc-2b28025cfc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>CORIELL</th>\n",
       "      <th>PRECEPT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cut10.0.txt.gz</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut10.1.txt.gz</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut10.2.txt.gz</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut10.3.txt.gz</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut10.4.txt.gz</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut10.5.txt.gz</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut10.6.txt.gz</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset        CORIELL PRECEPT\n",
       "file                          \n",
       "cut10.0.txt.gz       O       O\n",
       "cut10.1.txt.gz       O       O\n",
       "cut10.2.txt.gz       O       O\n",
       "cut10.3.txt.gz       O       O\n",
       "cut10.4.txt.gz       O       O\n",
       "cut10.5.txt.gz       O       O\n",
       "cut10.6.txt.gz       O       O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check wether we missed some files of not\n",
    "df=pd.DataFrame()\n",
    "for i in NEUROX:\n",
    "    check= \"ls /data/LNG/iwakih2/dataset/{dataset}/maf01rsq3_20Kcut/\"\n",
    "    bash =check.format(dataset=i)\n",
    "    res=subprocess.run(bash.split(\" \"), stdout=subprocess.PIPE)\n",
    "    files = [i for i in res.stdout.decode('utf-8').split('\\n') if 'gz' in i]\n",
    "    df = df.append(pd.DataFrame(data = {'dataset':i, 'file':files, 'yes':\"O\"}))\n",
    "tab=df.pivot(index='file', columns='dataset', values='yes')\n",
    "# By manual checks, no missing data (only different based on number of variants selected by maf and rsq thres)\n",
    "tab[tab.index.str.contains('cut10.', regex=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0de811-921a-4297-bdbb-2250c6149467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORIELL 2815231 /data/LNG/iwakih2/dataset/CORIELL/maf01rsq3.info\n",
      "\n",
      "PRECEPT 2781979 /data/LNG/iwakih2/dataset/PRECEPT/maf01rsq3.info\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if the maf01rsq3.info is ok\n",
    "for i in NEUROX:\n",
    "    check= \"wc -l /data/LNG/iwakih2/dataset/{dataset}/maf01rsq3.info\"\n",
    "    bash =check.format(dataset=i)\n",
    "    res=subprocess.run(bash.split(\" \"), stdout=subprocess.PIPE)\n",
    "    num=res.stdout.decode('utf-8')\n",
    "    print(i, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1479556e-c6a3-48be-9b2b-4c105a3ffedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOPA 7767315 /data/LNG/iwakih2/dataset/SCOPA/maf01rsq3.info\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in CHIP:\n",
    "    check= \"wc -l /data/LNG/iwakih2/dataset/{dataset}/maf01rsq3.info\"\n",
    "    bash =check.format(dataset=i)\n",
    "    res=subprocess.run(bash.split(\" \"), stdout=subprocess.PIPE)\n",
    "    num=res.stdout.decode('utf-8')\n",
    "    print(i, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe9e564-454e-4456-b13a-4eaba20491e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORIELL (340, 7)\n",
      "PRECEPT (318, 7)\n",
      "SCOPA (291, 7)\n",
      "All (949, 7)\n"
     ]
    }
   ],
   "source": [
    "# Derive genetic ID to match the clinical ID and genetic ID\n",
    "df = pd.DataFrame()\n",
    "for i in DATASET:\n",
    "    fam_place=\"/data/LNG/CORNELIS_TEMP/progression_GWAS/{dataset}/plink_files_hard/\"\n",
    "    fam=glob.glob(fam_place.format(dataset=i)+\"*.fam\")\n",
    "    t = pd.read_table(fam[0], delim_whitespace=True, header=None)\n",
    "    t['Cohort']=i\n",
    "    print(i, t.shape)\n",
    "    df = df.append(t)\n",
    "print('All', df.shape)\n",
    "!mkdir -p data\n",
    "df.to_csv(\"data/nonPPMI_geneticIDs.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330b9da-398a-466d-8635-5877f386500b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "151145d2-648d-4a71-a026-5e3580a9b1a2",
   "metadata": {},
   "source": [
    "# Phenotype\n",
    "\n",
    "Created by R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e1a53-307c-4121-bf2e-bd2f8a444cef",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "When importing vcf the default setting doesn't import GENOTYPED variants as their INFO is PASS;GENOTYPED. The argument to get genotyped variants is **--var-filter PASS . GENOTYPED**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fbe5e6a3-e90e-4bd1-8902-6c78a76fe8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic\n",
    "a = []\n",
    "\n",
    "DATASET = 'SCOPA'\n",
    "\n",
    "    # Create pfile for each chromosome\n",
    "\n",
    "for i in range(1,23):\n",
    "\n",
    "    CHRNUM = f'chr{i}'\n",
    "    script1 = [f\"\"\"\\\n",
    "plink2 \\\n",
    " --vcf '/data/CARD/PD/imputed_data/{DATASET}/{CHRNUM}.dose.vcf.gz' 'dosage=DS' \\\n",
    " --var-filter PASS . GENOTYPED\\\n",
    " --extract-if-info R2'>'=0.3 \\\n",
    " --mac 2 \\\n",
    " --make-pgen --out /data/CARD/projects/dysk_prog/logistic/{DATASET}.{CHRNUM} \\\n",
    "\"\"\"]\n",
    "    \n",
    "    # Analysis\n",
    "\n",
    "    for SEX in ['MALE', 'FEMALE', 'ALL']:\n",
    "        for MODEL in ['ADJ', 'NOADJ']:\n",
    "            \n",
    "            # define COV\n",
    "\n",
    "            if MODEL=='NOADJ':\n",
    "                COVS = 'PC1,PC2,PC3'\n",
    "            elif SEX=='ALL':\n",
    "                COVS = 'PD_AAO,Sex,HY,Disease_duration,PC1,PC2,PC3'\n",
    "            else:\n",
    "                COVS = 'PD_AAO,HY,Disease_duration,PC1,PC2,PC3'\n",
    "                \n",
    "            script1.append(f\"\"\"\\\n",
    "plink2 --pfile /data/CARD/projects/dysk_prog/logistic/{DATASET}.{CHRNUM} \\\n",
    " --glm 'no-firth' 'hide-covar' \\\n",
    " --freq \\\n",
    " --covar-variance-standardize \\\n",
    " --ci 0.95 \\\n",
    " --pheno data/{DATASET}_{SEX}.txt 'iid-only' --pheno-name Dyskinesia \\\n",
    " --covar data/{DATASET}_{SEX}.txt 'iid-only' --covar-name {COVS} \\\n",
    " --out /data/CARD/projects/dysk_prog/logistic/{DATASET}.{SEX}.{MODEL}.{CHRNUM} \\\n",
    "\"\"\")\n",
    "        \n",
    "    a.append(' ; '.join(script1))\n",
    "\n",
    "with open('swarm_logistics.txt', 'w') as f:\n",
    "    f.write('\\n'.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4216adc7-3b77-45b2-b529-e70058f8f696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688559 /data/CARD/projects/dysk_prog/logistic/SCOPA.ALL.ADJ.chr1.Dyskinesia.glm.logistic\n"
     ]
    }
   ],
   "source": [
    "!wc -l /data/CARD/projects/dysk_prog/logistic/SCOPA.ALL.ADJ.chr1.Dyskinesia.glm.logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e4d38bed-62cb-47c5-9c1a-3de480bc84c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30165593\\n']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitMultiJobs(['swarm_logistics.txt'], modules='plink/2.3-alpha', time='0:10:00', go=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9355f47d-06d5-4c33-9dc9-be3a6c3c2e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== index=0: jobID=30165593: swarm_logistics.txt  ===============\n",
      "N of Jobs: 11\n",
      "N_of not_COMPLETED: 0\n",
      "First 5 of longest Runtime job\n",
      "        Jobid Partition      State Nodes CPUs  Walltime   Runtime      MemReq  \\\n",
      "1  30165593_0     quick  COMPLETED     1    2  00:10:00  00:05:03  4.0GB/node   \n",
      "2  30165593_1     quick  COMPLETED     1    2  00:10:00  00:04:26  4.0GB/node   \n",
      "3  30165593_2     quick  COMPLETED     1    2  00:10:00  00:03:59  4.0GB/node   \n",
      "6  30165593_5     quick  COMPLETED     1    2  00:10:00  00:03:38  4.0GB/node   \n",
      "4  30165593_3     quick  COMPLETED     1    2  00:10:00  00:03:34  4.0GB/node   \n",
      "\n",
      "  MemUsed Nodelist  \n",
      "1   2.2GB   cn2864  \n",
      "2   2.4GB   cn2864  \n",
      "3   2.4GB   cn2864  \n",
      "6   2.1GB   cn2656  \n",
      "4   2.1GB   cn2864  \n",
      "Pending jobs[]\n"
     ]
    }
   ],
   "source": [
    "t = checkJobStatus(['30165593'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "214e52e5-8253-4b31-9893-693428f0b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear\n",
    "a = []\n",
    "\n",
    "for DATASET in ['SCOPA', 'CORIELL', 'PRECEPT']:\n",
    "    \n",
    "    # Create pfile for each chromosome\n",
    "\n",
    "    for i in range(1,23):\n",
    "\n",
    "        CHRNUM = f'chr{i}'\n",
    "        script1 = [f\"\"\"\\\n",
    "plink2 \\\n",
    " --vcf '/data/CARD/PD/imputed_data/{DATASET}/{CHRNUM}.dose.vcf.gz' 'dosage=DS' \\\n",
    " --var-filter PASS . GENOTYPED\\\n",
    " --extract-if-info R2'>'=0.3 \\\n",
    " --mac 2 \\\n",
    " --make-pgen --out /data/CARD/projects/dysk_prog/linear/{DATASET}.{CHRNUM} \\\n",
    "\"\"\"]\n",
    "\n",
    "        # Analysis\n",
    "\n",
    "        for SEX in ['MALE', 'FEMALE', 'ALL']:\n",
    "            for MODEL in ['ADJ', 'NOADJ']:\n",
    "\n",
    "                # define COV\n",
    "\n",
    "                if MODEL=='NOADJ':\n",
    "                    COVS = 'PC1,PC2,PC3'\n",
    "                elif SEX=='ALL':\n",
    "                    COVS = 'PD_AAO,Sex,HY,PC1,PC2,PC3'\n",
    "                else:\n",
    "                    COVS = 'PD_AAO,HY,PC1,PC2,PC3'\n",
    "                \n",
    "                # CORIELL doesn't have HY\n",
    "                if DATASET=='CORIELL':\n",
    "                    COVS = COVS.replace('HY,','')\n",
    "\n",
    "                script1.append(f\"\"\"\\\n",
    "plink2 --pfile /data/CARD/projects/dysk_prog/linear/{DATASET}.{CHRNUM} \\\n",
    " --glm 'no-firth' 'hide-covar' \\\n",
    " --freq \\\n",
    " --covar-variance-standardize \\\n",
    " --pheno data/{DATASET}_{SEX}.lin.txt 'iid-only' --pheno-name Disease_duration \\\n",
    " --covar data/{DATASET}_{SEX}.lin.txt 'iid-only' --covar-name {COVS} \\\n",
    " --out /data/CARD/projects/dysk_prog/linear/{DATASET}.{SEX}.{MODEL}.{CHRNUM} \\\n",
    "\"\"\")\n",
    "\n",
    "        a.append(' ; '.join(script1))\n",
    "\n",
    "with open('swarm_lin.txt', 'w') as f:\n",
    "    f.write('\\n'.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1db3548f-8726-4dd8-bd01-819ccc9774b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30167102\\n']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitMultiJobs(['swarm_lin.txt'], modules='plink/2.3-alpha', time='0:10:00', mem='8', go=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "145ffdfb-e161-41fc-bf2f-5b67d47456b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== index=0: jobID=30167102: swarm_lin.txt  ===============\n",
      "N of Jobs: 33\n",
      "N_of not_COMPLETED: 0\n",
      "First 5 of longest Runtime job\n",
      "          Jobid Partition      State Nodes CPUs  Walltime   Runtime  \\\n",
      "12  30167102_11     quick  COMPLETED     1    2  00:10:00  00:04:21   \n",
      "23  30167102_22     quick  COMPLETED     1    2  00:10:00  00:04:13   \n",
      "13  30167102_12     quick  COMPLETED     1    2  00:10:00  00:03:51   \n",
      "24  30167102_23     quick  COMPLETED     1    2  00:10:00  00:03:50   \n",
      "14  30167102_13     quick  COMPLETED     1    2  00:10:00  00:03:30   \n",
      "\n",
      "         MemReq MemUsed Nodelist  \n",
      "12  16.0GB/node   2.6GB   cn2656  \n",
      "23  16.0GB/node   2.4GB   cn2847  \n",
      "13  16.0GB/node   2.6GB   cn2656  \n",
      "24  16.0GB/node   2.3GB   cn2847  \n",
      "14  16.0GB/node   2.5GB   cn2656  \n",
      "Pending jobs[]\n"
     ]
    }
   ],
   "source": [
    "t = checkJobStatus(['30167102'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48f352d1-0314-4d3b-94a1-41598d0174a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival\n",
    "\n",
    "with open('swarm_surv.txt', 'w') as f:\n",
    "    for DATASET in ['SCOPA', 'CORIELL', 'PRECEPT']:\n",
    "        infofolder=f\"/data/LNG/iwakih2/dataset/{DATASET}/maf01rsq3_20Kcut\"\n",
    "        FILES = glob.glob(f'{infofolder}/cut*txt.gz',)\n",
    "\n",
    "        for FILE in FILES:\n",
    "            for SEX in ['ALL']:\n",
    "                for MODEL in ['ADJ', 'NOADJ']:\n",
    "\n",
    "                    # define COV\n",
    "\n",
    "                    if MODEL=='NOADJ':\n",
    "                        COVS = 'PC1+PC2+PC3'\n",
    "                    else:\n",
    "                        COVS = 'PD_AAO+Sex+HY+PC1+PC2+PC3'\n",
    "\n",
    "                    # CORIELL doesn't have HY\n",
    "                    if DATASET=='CORIELL':\n",
    "                        COVS = COVS.replace('HY+','')\n",
    "\n",
    "\n",
    "                    line = f\"Rscript --vanilla surv.R '{MODEL};Dyskinesia;{COVS};{FILE};data/{DATASET}_{SEX}.surv.txt;/data//CARD/projects/dysk_prog/surv/{DATASET}'\\n\"\n",
    "                    f.write(line) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "594ae614-e001-4d01-b3b2-e81da0c7bb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27598592\\n']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitMultiJobs(['swarm_surv.txt'], modules='R/4.1.0', time='3:00:00', mem=4, go=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "157db238-fe80-460e-bc66-3f060c17e40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== index=0: jobID=27598592: swarm_surv.txt  ===============\n",
      "N of Jobs: 701\n",
      "N_of not_COMPLETED: 9\n",
      "First 5 of longest Runtime job\n",
      "            Jobid Partition      State Nodes CPUs  Walltime   Runtime  \\\n",
      "74    27598592_73     quick  COMPLETED     1    2  03:00:00  00:19:07   \n",
      "119  27598592_118     quick  COMPLETED     1    2  03:00:00  00:18:55   \n",
      "115  27598592_114     quick  COMPLETED     1    2  03:00:00  00:18:48   \n",
      "179  27598592_178     quick  COMPLETED     1    2  03:00:00  00:18:47   \n",
      "79    27598592_78     quick  COMPLETED     1    2  03:00:00  00:18:44   \n",
      "\n",
      "         MemReq MemUsed Nodelist  \n",
      "74   8.0GB/node   0.6GB   cn2616  \n",
      "119  8.0GB/node   0.6GB   cn2870  \n",
      "115  8.0GB/node   0.6GB   cn2870  \n",
      "179  8.0GB/node   0.6GB   cn2606  \n",
      "79   8.0GB/node   0.6GB   cn2616  \n",
      "Pending jobs[]\n"
     ]
    }
   ],
   "source": [
    "t = checkJobStatus(['27598592'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "42db3a43-2992-4271-8980-f7b85d7bc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival (Male, Female version) ## Added \n",
    "\n",
    "with open('swarm_surv2.txt', 'w') as f:\n",
    "    for DATASET in ['SCOPA', 'CORIELL', 'PRECEPT']:\n",
    "        infofolder=f\"/data/LNG/iwakih2/dataset/{DATASET}/maf01rsq3_20Kcut\"\n",
    "        FILES = glob.glob(f'{infofolder}/cut*txt.gz',)\n",
    "\n",
    "        for FILE in FILES:\n",
    "            for SEX in ['MALE', 'FEMALE']:\n",
    "                for MODEL in ['ADJ', 'NOADJ']:\n",
    "\n",
    "                    # define COV\n",
    "\n",
    "                    if MODEL=='NOADJ':\n",
    "                        COVS = 'PC1+PC2+PC3'\n",
    "                    else:\n",
    "                        COVS = 'PD_AAO+HY+PC1+PC2+PC3'\n",
    "\n",
    "                    # CORIELL doesn't have HY\n",
    "                    if DATASET=='CORIELL':\n",
    "                        COVS = COVS.replace('HY+','')\n",
    "\n",
    "\n",
    "                    line = f\"Rscript --vanilla surv.R '{MODEL};Dyskinesia;{COVS};{FILE};data/{DATASET}_{SEX}.surv.txt;/data//CARD/projects/dysk_prog/surv/{DATASET}'\\n\"\n",
    "                    f.write(line) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4fb02d21-ef6d-4739-aa1d-642ddd85ffc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30169626\\n']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitMultiJobs(['swarm_surv2.txt'], modules='R/4.1.0', time='1:00:00', mem=4,bundle=2,  go=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cc8c2069-cb6c-473a-8a38-97ccfa74f41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== index=0: jobID=30169626: swarm_surv2.txt  ===============\n",
      "N of Jobs: 701\n",
      "N_of not_COMPLETED: 0\n",
      "First 5 of longest Runtime job\n",
      "            Jobid Partition      State Nodes CPUs  Walltime   Runtime  \\\n",
      "567  30169626_566     quick  COMPLETED     1    2  02:00:00  00:37:17   \n",
      "548  30169626_547     quick  COMPLETED     1    2  02:00:00  00:37:16   \n",
      "547  30169626_546     quick  COMPLETED     1    2  02:00:00  00:37:13   \n",
      "550  30169626_549     quick  COMPLETED     1    2  02:00:00  00:36:58   \n",
      "552  30169626_551     quick  COMPLETED     1    2  02:00:00  00:36:57   \n",
      "\n",
      "         MemReq MemUsed Nodelist  \n",
      "567  8.0GB/node   0.6GB   cn0724  \n",
      "548  8.0GB/node   0.6GB   cn0704  \n",
      "547  8.0GB/node   0.6GB   cn0704  \n",
      "550  8.0GB/node   0.6GB   cn0704  \n",
      "552  8.0GB/node   0.6GB   cn0704  \n",
      "Pending jobs[]\n"
     ]
    }
   ],
   "source": [
    "t = checkJobStatus(['30169626'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61722a00-531a-4943-b3e6-699b1bda1872",
   "metadata": {},
   "source": [
    "# Tareget analyses\n",
    "\n",
    "For 90 risk snps and GBA, LRRK2 scores\n",
    "\n",
    "90 risk snps were already derived in the previous research. Need to create GBA, LRRK2 scores\n",
    "\n",
    "*Analyses on specific genes focus on GBA and LRRK2 variants associated with PD increased/decreased risk. The carrier status of these variants are collapsed into three single variables: carrier status of GBA risk variants, carrier status of LRRK2 risk variants and carrier status of LRRK2 protective haplotype. The variants that have been included are: T369M, E326K, N370S and L444P for GBA; G2019S, M1646T and R1441C/G for LRRK2 risk variants and R1398H as a tagging variant for LRRK2 protective haplotype.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d57f7b-0148-4028-bd92-6c5de1e556b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d4f5c1e4-c4e0-4a5a-b7f8-df670b4b11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target 2 adding the cumulative GBA, LRRK2 scores to PRS90 and META5 PRS\n",
    "GBAs = {0:['rs2230288', 'E326K', '1:155206167', 'T'],\n",
    "        1:['rs76763715', 'N370S', '1:155205634', 'C'],\n",
    "        2:['rs75548401', 'T369zM','1:155206037', 'A'],\n",
    "        3:['rs1569861490', 'L444P', '1:12064609', 'C']}\n",
    "LRRK2s = {0:['rs34637584', 'G2010S', '12:40734202', 'A'],\n",
    "          1:['rs35303786', 'M1646T', '12:40713899', 'C'],\n",
    "          2:['rs33939927', 'R1441C', '12:13715851', 'T'],\n",
    "          3:['rs33939927', 'R1441G', '12:13715851', 'G'],\n",
    "          4:['rs7133914', 'R1398H', '12:40702911', 'A']} # protective\n",
    "\n",
    "GBAs = pd.DataFrame.from_dict(GBAs, orient='index', columns=['rsid','name', 'ID', 'alt'])\n",
    "LRRK2s=pd.DataFrame.from_dict(LRRK2s, orient='index', columns=['rsid','name', 'ID', 'alt'])\n",
    "GBAs[['ID', 'alt']].to_csv('chr1.target.txt', sep='\\t', index=False, header=False)\n",
    "LRRK2s[['ID', 'alt']].to_csv('chr12.target.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8be9f7d0-bda8-4908-87a8-b3bb2fb9e54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory '/data/CARD/projects/dysk_prog/target2': File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /data/CARD/projects/dysk_prog/target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "46b580a5-bd5b-4591-8bd8-da349f0a87a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXEC_TIME in sec: 0.044 : EXEC_TIME in sec: 0.013 : EXEC_TIME in sec: 0.037 : EXEC_TIME in sec: 0.011 : EXEC_TIME in sec: 0.03 : EXEC_TIME in sec: 0.011 : EXEC_TIME in sec: 0.038 : EXEC_TIME in sec: 0.011 : EXEC_TIME in sec: 0.029 : EXEC_TIME in sec: 0.011 : EXEC_TIME in sec: 0.036 : EXEC_TIME in sec: 0.011 : "
     ]
    }
   ],
   "source": [
    "# Target2\n",
    "for DATASET in ['SCOPA', 'CORIELL', 'PRECEPT']:\n",
    "    df_prs = pd.read_csv(f'/data/LNG/iwakih2/dataset/{DATASET}/target/all.txt', sep='\\t', index_col='IID')\n",
    "    a = [df_prs]\n",
    "    # Create pfile for each chromosome\n",
    "    \n",
    "    for i in [1,12]:\n",
    "        CHRNUM = f'chr{i}'\n",
    "        \n",
    "        # derive variants from vcf\n",
    "        df = pd.read_csv(f'{CHRNUM}.target.txt', header=None, sep='\\t', names=['ID', 'Alt'])\n",
    "        script1 = f\"\"\"\\\n",
    "bcftools view -r {\",\".join(df.ID.unique())} /data/CARD/PD/imputed_data/{DATASET}/{CHRNUM}.dose.vcf.gz\\\n",
    " -Oz -o /data/CARD/projects/dysk_prog/target2/{DATASET}.{CHRNUM}.vcf.gz ; \\\n",
    "\"\"\"\n",
    "        t=submitTerminal(script1)\n",
    "        \n",
    "        \n",
    "        # create raw file with INFO filter\n",
    "        script2 = f\"\"\"\\\n",
    "plink2\\\n",
    " --vcf /data/CARD/projects/dysk_prog/target2/{DATASET}.{CHRNUM}.vcf.gz dosage=DS\\\n",
    " --var-filter PASS . GENOTYPED\\\n",
    " --extract-if-info R2>=0.3\\\n",
    " --export A --out /data/CARD/projects/dysk_prog/target2/{DATASET}.{CHRNUM}\\\n",
    " --export-allele {CHRNUM}.target.txt\"\"\"\n",
    "        t=submitTerminal(script2)\n",
    "        \n",
    "        \n",
    "        if CHRNUM=='chr1':\n",
    "            # GBA\n",
    "            d = pd.read_csv(f'/data/CARD/projects/dysk_prog/target2/{DATASET}.{CHRNUM}.raw', sep='\\t')\n",
    "            relevant_columns = np.intersect1d(GBAs.ID+'_'+GBAs.alt, d.columns)\n",
    "            if len(relevant_columns)>0:\n",
    "                d['GBAr_N_A'] = (d[relevant_columns].sum(axis=1)>0)*1\n",
    "                # Usually SNP_REF_ALT but since this is not SNP, give _N_A instead.\n",
    "            else:\n",
    "                d['GBAr_N_A'] = np.nan\n",
    "            \n",
    "            a.append(d[['IID', 'GBAr_N_A']].set_index('IID'))\n",
    "            \n",
    "            \n",
    "        if CHRNUM=='chr12':\n",
    "            # LRRK2 risk\n",
    "            d = pd.read_csv(f'/data/CARD/projects/dysk_prog/target2/{DATASET}.{CHRNUM}.raw', sep='\\t')\n",
    "            relevant_columns = np.intersect1d(LRRK2s.ID+'_'+LRRK2s.alt, d.columns).tolist()\n",
    "            relevant_columns.remove('12:40702911_A')\n",
    "            if len(relevant_columns)>0:\n",
    "                d['LRRK2r_N_A'] = (d[relevant_columns].sum(axis=1)>0)*1\n",
    "            else:\n",
    "                d['LRRK2r_N_A'] = np.nan\n",
    "\n",
    "            # LRRK2 protective\n",
    "            if d.columns.isin(['12:40702911_A']).sum().sum()>0:\n",
    "                d['LRRK2p_N_A'] = (d['12:40702911_A']>0)*1\n",
    "            else:\n",
    "                d['LRRK2p_N_A'] = np.nan\n",
    "            \n",
    "            a.append(d[['IID', 'LRRK2r_N_A', 'LRRK2p_N_A']].set_index('IID'))\n",
    "        \n",
    "        \n",
    "        \n",
    "        pd.concat(a, axis=1).to_csv(f'/data/CARD/projects/dysk_prog/target2/{DATASET}.all.txt', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc5def-55ad-4816-bdbe-4d88687a0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Aanalysis - Target\n",
    "for DATASET in ['SCOPA', 'CORIELL', 'PRECEPT']:\n",
    "    infofolder=f\"/data/LNG/iwakih2/dataset/{DATASET}/maf01rsq3_20Kcut\"\n",
    "    FILES = [f\"/data/CARD/projects/dysk_prog/target2/{DATASET}.all.txt\"]\n",
    "\n",
    "    for FILE in FILES:\n",
    "        for SEX in ['ALL', 'MALE', 'FEMALE']:\n",
    "            for MODEL in ['ADJ', 'NOADJ']:\n",
    "\n",
    "                # define COV\n",
    "\n",
    "                if MODEL=='NOADJ':\n",
    "                    COVS = 'PC1+PC2+PC3'\n",
    "                    \n",
    "                elif SEX=='ALL':\n",
    "                    COVS = 'PD_AAO+Sex+HY+PC1+PC2+PC3'\n",
    "                else:\n",
    "                    COVS = 'PD_AAO+HY+PC1+PC2+PC3'\n",
    "                \n",
    "                # CORIELL doesn't have HY\n",
    "                if DATASET=='CORIELL':\n",
    "                    COVS = COVS.replace('HY+','')\n",
    "                    \n",
    "                # survival\n",
    "                line = f\"Rscript --vanilla surv_target.R {MODEL};Dyskinesia;{COVS};{FILE};data/{DATASET}_{SEX}.surv.txt;/data/CARD/projects/dysk_prog/target2/result\"\n",
    "                print(line)\n",
    "                t=submitTerminal(line)\n",
    "                \n",
    "                # linear\n",
    "                line = f\"Rscript --vanilla lin_target.R {MODEL};Disease_duration;{COVS};{FILE};data/{DATASET}_{SEX}.lin.txt;/data/CARD/projects/dysk_prog/target2/result\"\n",
    "                print(line)\n",
    "                t=submitTerminal(line)\n",
    "                \n",
    "                # logistic\n",
    "                if DATASET=='SCOPA':\n",
    "                    COVS=COVS + '+Disease_duration'\n",
    "                    line = f\"Rscript --vanilla logis_target.R {MODEL};Dyskinesia;{COVS};{FILE};data/{DATASET}_{SEX}.txt;/data/CARD/projects/dysk_prog/target2/result\"\n",
    "                    print(line)\n",
    "                    t=submitTerminal(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9e106128-2847-41e6-a49e-44941a4a62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORIELL.ALL.ADJ.Disease_duration.lin.txt\n",
      "CORIELL.ALL.ADJ.Dyskinesia.cox.txt\n",
      "CORIELL.ALL.NOADJ.Disease_duration.lin.txt\n",
      "CORIELL.ALL.NOADJ.Dyskinesia.cox.txt\n",
      "CORIELL.FEMALE.ADJ.Disease_duration.lin.txt\n",
      "CORIELL.FEMALE.ADJ.Dyskinesia.cox.txt\n",
      "CORIELL.FEMALE.NOADJ.Disease_duration.lin.txt\n",
      "CORIELL.FEMALE.NOADJ.Dyskinesia.cox.txt\n",
      "CORIELL.MALE.ADJ.Disease_duration.lin.txt\n",
      "CORIELL.MALE.ADJ.Dyskinesia.cox.txt\n",
      "CORIELL.MALE.NOADJ.Disease_duration.lin.txt\n",
      "CORIELL.MALE.NOADJ.Dyskinesia.cox.txt\n",
      "PRECEPT.ALL.ADJ.Disease_duration.lin.txt\n",
      "PRECEPT.ALL.ADJ.Dyskinesia.cox.txt\n",
      "PRECEPT.ALL.NOADJ.Disease_duration.lin.txt\n",
      "PRECEPT.ALL.NOADJ.Dyskinesia.cox.txt\n",
      "PRECEPT.FEMALE.ADJ.Disease_duration.lin.txt\n",
      "PRECEPT.FEMALE.ADJ.Dyskinesia.cox.txt\n",
      "PRECEPT.FEMALE.NOADJ.Disease_duration.lin.txt\n",
      "PRECEPT.FEMALE.NOADJ.Dyskinesia.cox.txt\n",
      "PRECEPT.MALE.ADJ.Disease_duration.lin.txt\n",
      "PRECEPT.MALE.ADJ.Dyskinesia.cox.txt\n",
      "PRECEPT.MALE.NOADJ.Disease_duration.lin.txt\n",
      "PRECEPT.MALE.NOADJ.Dyskinesia.cox.txt\n",
      "SCOPA.ALL.ADJ.Disease_duration.lin.txt\n",
      "SCOPA.ALL.ADJ.Dyskinesia.cox.txt\n",
      "SCOPA.ALL.ADJ.Dyskinesia.lgs.txt\n",
      "SCOPA.ALL.NOADJ.Disease_duration.lin.txt\n",
      "SCOPA.ALL.NOADJ.Dyskinesia.cox.txt\n",
      "SCOPA.ALL.NOADJ.Dyskinesia.lgs.txt\n",
      "SCOPA.FEMALE.ADJ.Disease_duration.lin.txt\n",
      "SCOPA.FEMALE.ADJ.Dyskinesia.cox.txt\n",
      "SCOPA.FEMALE.ADJ.Dyskinesia.lgs.txt\n",
      "SCOPA.FEMALE.NOADJ.Disease_duration.lin.txt\n",
      "SCOPA.FEMALE.NOADJ.Dyskinesia.cox.txt\n",
      "SCOPA.FEMALE.NOADJ.Dyskinesia.lgs.txt\n",
      "SCOPA.MALE.ADJ.Disease_duration.lin.txt\n",
      "SCOPA.MALE.ADJ.Dyskinesia.cox.txt\n",
      "SCOPA.MALE.ADJ.Dyskinesia.lgs.txt\n",
      "SCOPA.MALE.NOADJ.Disease_duration.lin.txt\n",
      "SCOPA.MALE.NOADJ.Dyskinesia.cox.txt\n",
      "SCOPA.MALE.NOADJ.Dyskinesia.lgs.txt\n"
     ]
    }
   ],
   "source": [
    "# !rm /data/CARD/projects/dysk_prog/target2/lgs/*\n",
    "!ls /data/CARD/projects/dysk_prog/target2/result/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b68b78-1415-47be-bd1d-7782531506f5",
   "metadata": {},
   "source": [
    "# Combine results\n",
    "\n",
    "Combine the GWAS results and save them into \"RES\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b40f04bc-02fd-44fa-aac8-4a0ae6c599e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /data/CARD/projects/dysk_prog/RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8bc8e00e-8605-40ca-b616-df702932fe5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for DATASET in  CORIELL SCOPA PRECEPT ;do\n",
    "    for SEX in ALL MALE FEMALE ;do\n",
    "        for MODEL in ADJ NOADJ ;do\n",
    "            TAIL=Dyskinesia.cox.txt\n",
    "            awk 'FNR==1 && NR!=1{next;}{print}' /data/CARD/projects/dysk_prog/surv/${DATASET}/${DATASET}.${SEX}.${MODEL}.*.${TAIL} > /data/CARD/projects/dysk_prog/RES/${DATASET}.${SEX}.${MODEL}.${TAIL}\n",
    "        done\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9e255dea-bcd6-40f4-9834-a5250bd87d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_lin_outputs(DATASET, SEX, MODEL):\n",
    "    d = pd.DataFrame()\n",
    "    for i in range(1,23):\n",
    "        \n",
    "        d1 = pd.read_csv(f'/data/CARD/projects/dysk_prog/linear/{DATASET}.{SEX}.{MODEL}.chr{i}.Disease_duration.glm.linear', sep='\\t')\n",
    "        d2 = pd.read_csv(f'/data/CARD/projects/dysk_prog/linear/{DATASET}.{SEX}.{MODEL}.chr{i}.afreq', sep='\\t')\n",
    "        if d1.shape[0] != d2.shape[0]:\n",
    "            print(f'ERROR for {DATASET}.{SEX}.{MODEL}.chr{i}')\n",
    "        else:\n",
    "            d1['ALT_Frq'] = d2.ALT_FREQS\n",
    "            d1['BETA'] = d1.BETA.where(d1.ALT==d1.A1, other=-d1.BETA)\n",
    "            d1['T_STAT'] = d1.T_STAT.where(d1.ALT==d1.A1, other=-d1.T_STAT)\n",
    "            d1 = d1.drop(columns=['A1'])\n",
    "            d = d.append(d1)\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8f00691c-29c5-4343-840d-f9ae9cdbd5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for DATASET in ['SCOPA', 'CORIELL', 'PRECEPT']:\n",
    "    for SEX in ['ALL', 'MALE', 'FEMALE']:\n",
    "        for MODEL in ['ADJ', 'NOADJ']:\n",
    "            d = combine_lin_outputs(DATASET, SEX, MODEL)\n",
    "            d.to_csv(f'/data/CARD/projects/dysk_prog/RES/{DATASET}.{SEX}.{MODEL}.Disease_duration.glm.linear.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "053f2fca-12ef-40f2-af8d-81ece722a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_lgs_outputs(DATASET, SEX, MODEL):\n",
    "    d = pd.DataFrame()\n",
    "    for i in range(1,23):       \n",
    "        d1 = pd.read_csv(f'/data/CARD/projects/dysk_prog/logistic/{DATASET}.{SEX}.{MODEL}.chr{i}.Dyskinesia.glm.logistic', sep='\\t', low_memory=False)\n",
    "        d2 = pd.read_csv(f'/data/CARD/projects/dysk_prog/logistic/{DATASET}.{SEX}.{MODEL}.chr{i}.afreq', sep='\\t', low_memory=False)\n",
    "        if d1.shape[0] != d2.shape[0]:\n",
    "            print(f'ERROR for {DATASET}.{SEX}.{MODEL}.chr{i}')\n",
    "        else:\n",
    "            print(f'{DATASET}.{SEX}.{MODEL}.chr{i}')\n",
    "            d1['ALT_Frq'] = d2.ALT_FREQS\n",
    "            OR = pd.to_numeric(d1.OR, errors='coerce')\n",
    "            d1['OR'] = OR.where(d1.ALT==d1.A1, other=1/OR)\n",
    "            d1['Z_STAT'] = d1.Z_STAT.where(d1.ALT==d1.A1, other=-d1.Z_STAT)\n",
    "            L95 = pd.to_numeric(d1.L95, errors='coerce')\n",
    "            U95 = pd.to_numeric(d1.U95, errors='coerce')\n",
    "            LL = L95.where(d1.ALT==d1.A1, other=1/U95)\n",
    "            UL = U95.where(d1.ALT==d1.A1, other=1/L95)\n",
    "            d1['L95'] = LL\n",
    "            d1['U95'] = UL\n",
    "            d1 = d1.drop(columns=['A1'])\n",
    "            d = d.append(d1)\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8b68a-df67-4eff-b596-e6d2eb572298",
   "metadata": {},
   "outputs": [],
   "source": [
    "for DATASET in ['SCOPA']:\n",
    "    for SEX in ['ALL', 'MALE', 'FEMALE']:\n",
    "        for MODEL in ['ADJ', 'NOADJ']:\n",
    "            d = combine_lgs_outputs(DATASET, SEX, MODEL)\n",
    "            d.to_csv(f'/data/CARD/projects/dysk_prog/RES/{DATASET}.{SEX}.{MODEL}.Dyskinesia.glm.logitstic.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fab957-dd6b-4f3a-8ad4-ce238b918944",
   "metadata": {},
   "source": [
    "# Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "06c5b4bb-46fc-4ab5-bd74-7bb81dbe742c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/CARD/projects/dysk_prog/RES/PRECEPT.ALL.ADJ.Dyskinesia.cox.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/PRECEPT.ALL.NOADJ.Disease_duration.glm.linear.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/CORIELL.ALL.ADJ.Disease_duration.glm.linear.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/SCOPA.ALL.NOADJ.Dyskinesia.cox.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/PRECEPT.ALL.ADJ.Disease_duration.glm.linear.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/SCOPA.ALL.ADJ.Disease_duration.glm.linear.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/SCOPA.ALL.ADJ.Dyskinesia.cox.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/CORIELL.ALL.ADJ.Dyskinesia.cox.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/CORIELL.ALL.NOADJ.Dyskinesia.cox.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/SCOPA.ALL.NOADJ.Disease_duration.glm.linear.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/CORIELL.ALL.NOADJ.Disease_duration.glm.linear.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/SCOPA.ALL.NOADJ.Dyskinesia.glm.logitstic.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/PRECEPT.ALL.NOADJ.Dyskinesia.cox.txt',\n",
       " '/data/CARD/projects/dysk_prog/RES/SCOPA.ALL.ADJ.Dyskinesia.glm.logitstic.txt']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILES = glob.glob(f'/data/CARD/projects/dysk_prog/RES/*ALL*')\n",
    "FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ccc2c900-fed6-4b57-992d-54737bc6f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('swarm_qc.txt', 'w') as f:\n",
    "    for FILE in FILES:\n",
    "        f.write(f'Rscript --vanilla QQMH.txt {FILE} lambda.txt\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "787d05bc-7ac2-4a34-b38f-951bd1d5cba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30283944\\n']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitMultiJobs(['swarm_qc.txt'], modules='R/4.1.0', time='0:30:00', mem=12, go=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e43c49bc-c05a-4b04-b581-c895d4cf7045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== index=0: jobID=27626023: swarm_qc.txt  ===============\n",
      "N of Jobs: 7\n",
      "N_of not_COMPLETED: 0\n",
      "First 5 of longest Runtime job\n",
      "        Jobid Partition      State Nodes CPUs  Walltime   Runtime  \\\n",
      "5  27626023_4     quick  COMPLETED     1    2  01:00:00  00:09:19   \n",
      "6  27626023_5     quick  COMPLETED     1    2  01:00:00  00:09:09   \n",
      "7  27626023_6     quick  COMPLETED     1    2  01:00:00  00:08:56   \n",
      "3  27626023_2     quick  COMPLETED     1    2  01:00:00  00:08:38   \n",
      "2  27626023_1     quick  COMPLETED     1    2  01:00:00  00:08:24   \n",
      "\n",
      "        MemReq MemUsed Nodelist  \n",
      "5  24.0GB/node   9.4GB   cn2589  \n",
      "6  24.0GB/node  10.4GB   cn2589  \n",
      "7  24.0GB/node   9.4GB   cn2589  \n",
      "3  24.0GB/node  10.4GB   cn2686  \n",
      "2  24.0GB/node   9.8GB   cn2686  \n",
      "Pending jobs[]\n"
     ]
    }
   ],
   "source": [
    "t = checkJobStatus(['30283944'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c4ce3-a51f-4dd3-9c5c-21efb69a74ca",
   "metadata": {},
   "source": [
    "# Compress folders\n",
    "\n",
    "after compress folders, do the following to download the files\n",
    "\n",
    "        scp helix.nih.gov:/data/CARD/projects/dysk_prog/target.tar.gz  /Users/iwakih2/Downloads\n",
    "        scp helix.nih.gov:/data/CARD/projects/dysk_prog/md5sum_for*  /Users/iwakih2/Downloads\n",
    "        scp helix.nih.gov:/data/CARD/projects/dysk_prog/RES.tar.gz  /Users/iwakih2/Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b9cb5e52-22bb-4610-8f19-b37e732dc28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /data/CARD/projects/dysk_prog/target2\n",
    "tar -zcf target.tar.gz result/\n",
    "mv target.tar.gz ../target.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f578ed3a-ffc4-42a6-8f19-821d0af6da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /data/CARD/projects/dysk_prog\n",
    "tar -zcf RES.tar.gz RES/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "705b0363-a945-4135-8648-3c46ab402b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RES\t    RES_old  logistic\t\t surv\t\ttarget2\n",
      "RES.tar.gz  linear   md5sum_for_RES.txt  target.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!ls /data/CARD/projects/dysk_prog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "37a07c60-76ad-4a6b-b47b-685656dd9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!md5sum /data/CARD/projects/dysk_prog/RES.tar.gz > /data/CARD/projects/dysk_prog/md5sum_for_RES.txt\n",
    "!md5sum /data/CARD/projects/dysk_prog/target.tar.gz > /data/CARD/projects/dysk_prog/md5sum_for_target.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2252e162-a78e-4f58-8c52-a32279a5af0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RES\t    RES_old  logistic\t\t md5sum_for_target.txt\ttarget.tar.gz\n",
      "RES.tar.gz  linear   md5sum_for_RES.txt  surv\t\t\ttarget2\n"
     ]
    }
   ],
   "source": [
    "!ls /data/CARD/projects/dysk_prog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a166cdc4-fe33-44a1-89e6-4d013c61b787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh: Could not resolve hostname nialng-02178851: Name or service not known\n",
      "lost connection\n"
     ]
    }
   ],
   "source": [
    "!scp  /data/CARD/projects/dysk_prog/target.tar.gz NIALNG-02178851:/Users/iwakih2/Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f2000b1e-92d3-4aad-92b9-d4fc496e85c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/gsfs9/users/iwakih2/dyskinesia\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d99b499-1b72-4c14-8c52-3811578c0d1d",
   "metadata": {},
   "source": [
    "# Additional Analysis 1\n",
    "\n",
    "Ever vs Never Dyskinesia analysis of logistic regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d163e25-c8ee-4d8b-ae9c-b18c5f3a5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for DATASET in ['SCOPA', 'CORIELL', 'PRECEPT']:\n",
    "    for SEX in ['MALE', 'FEMALE', 'ALL']:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "116d8675-e72a-4232-ac15-1d270c4efb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic\n",
    "!mkdir -p /data/CARD/projects/dysk_prog/logistic_en\n",
    "a = []\n",
    "\n",
    "for DATASET in ['SCOPA', 'CORIELL', 'PRECEPT']:\n",
    "    for i in range(1,23):\n",
    "        CHRNUM = f'chr{i}'\n",
    "        script1 = [f\"\"\"\\\n",
    "plink2 \\\n",
    " --vcf '/data/CARD/PD/imputed_data/{DATASET}/{CHRNUM}.dose.vcf.gz' 'dosage=DS' \\\n",
    " --var-filter PASS . GENOTYPED \\\n",
    " --extract-if-info R2'>'=0.3 \\\n",
    " --mac 2 \\\n",
    " --make-pgen --out /data/CARD/projects/dysk_prog/logistic_en/{DATASET}.{CHRNUM} \\\n",
    " --threads 2 \\\n",
    "\"\"\"]\n",
    "    \n",
    "        for SEX in ['MALE', 'FEMALE', 'ALL']:\n",
    "            for MODEL in ['ADJ', 'NOADJ']:\n",
    "\n",
    "                # define COV\n",
    "\n",
    "                if MODEL=='NOADJ':\n",
    "                    COVS = 'PC1,PC2,PC3'\n",
    "                elif SEX=='ALL':\n",
    "                    COVS = 'PD_AAO,Sex,HY,Disease_duration,PC1,PC2,PC3'\n",
    "                else:\n",
    "                    COVS = 'PD_AAO,HY,Disease_duration,PC1,PC2,PC3'\n",
    "\n",
    "                script1.append(f\"\"\"\\\n",
    "plink2 --pfile /data/CARD/projects/dysk_prog/logistic_en/{DATASET}.{CHRNUM} \\\n",
    " --glm 'no-firth' 'hide-covar' \\\n",
    " --freq \\\n",
    " --covar-variance-standardize \\\n",
    " --ci 0.95 \\\n",
    " --pheno data/{DATASET}_{SEX}_en.txt 'iid-only' --pheno-name Dyskinesia \\\n",
    " --covar data/{DATASET}_{SEX}_en.txt 'iid-only' --covar-name {COVS} \\\n",
    " --out /data/CARD/projects/dysk_prog/logistic_en/{DATASET}.{SEX}.{MODEL}.{CHRNUM} \\\n",
    " --threads 2 \\\n",
    "\"\"\")\n",
    "\n",
    "        a.append(' ; '.join(script1))\n",
    "\n",
    "with open('swarm_logistics_en.txt', 'w') as f:\n",
    "    f.write('\\n'.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57150ff4-da4f-4d47-b71b-453ad5311673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['34309884\\n']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitMultiJobs(['swarm_logistics_en.txt'], modules='plink/2.3-alpha', time='0:20:00', mem=8, go=True) # bundle next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86942eea-9c8f-4f39-b4d0-4a3fa432a41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== index=0: jobID=34309884: swarm_logistics_en.txt  ===============\n",
      "N of Jobs: 33\n",
      "N_of not_COMPLETED: 0\n",
      "First 5 of longest Runtime job\n",
      "          Jobid Partition      State Nodes CPUs  Walltime   Runtime  \\\n",
      "1    34309884_0     quick  COMPLETED     1    2  00:20:00  00:05:54   \n",
      "12  34309884_11     quick  COMPLETED     1    2  00:20:00  00:05:26   \n",
      "2    34309884_1     quick  COMPLETED     1    2  00:20:00  00:05:18   \n",
      "23  34309884_22     quick  COMPLETED     1    2  00:20:00  00:04:59   \n",
      "3    34309884_2     quick  COMPLETED     1    2  00:20:00  00:04:39   \n",
      "\n",
      "         MemReq MemUsed Nodelist  \n",
      "1   16.0GB/node   2.1GB   cn2714  \n",
      "12  16.0GB/node   2.6GB   cn2874  \n",
      "2   16.0GB/node   2.1GB   cn2714  \n",
      "23  16.0GB/node   2.3GB   cn2876  \n",
      "3   16.0GB/node   2.1GB   cn2714  \n",
      "Pending jobs[]\n"
     ]
    }
   ],
   "source": [
    "t = checkJobStatus(['34309884'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f0c2d-1754-47fe-90f0-ff14c71bf5fa",
   "metadata": {},
   "source": [
    "# Additional Analysis 2\n",
    "Ever vs Never (Target analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda1574-020b-4169-bc8a-0485f7babb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Aanalysis - Target\n",
    "!mkdir -p /data/CARD/projects/dysk_prog/target2/result_en\n",
    "for DATASET in ['SCOPA', 'CORIELL', 'PRECEPT']:\n",
    "    infofolder=f\"/data/LNG/iwakih2/dataset/{DATASET}/maf01rsq3_20Kcut\"\n",
    "    FILES = [f\"/data/CARD/projects/dysk_prog/target2/{DATASET}.all.txt\"]\n",
    "\n",
    "    for FILE in FILES:\n",
    "        for SEX in ['ALL', 'MALE', 'FEMALE']:\n",
    "            for MODEL in ['ADJ', 'NOADJ']:\n",
    "\n",
    "                # define COV\n",
    "\n",
    "                if MODEL=='NOADJ':\n",
    "                    COVS = 'PC1+PC2+PC3'\n",
    "                    \n",
    "                elif SEX=='ALL':\n",
    "                    COVS = 'PD_AAO+Sex+HY+PC1+PC2+PC3'\n",
    "                else:\n",
    "                    COVS = 'PD_AAO+HY+PC1+PC2+PC3'\n",
    "                \n",
    "                # CORIELL doesn't have HY\n",
    "                if DATASET=='CORIELL':\n",
    "                    COVS = COVS.replace('HY+','')\n",
    "                                \n",
    "                # logistic\n",
    "                COVS=COVS + '+Disease_duration'\n",
    "                line = f\"Rscript --vanilla logis_target.R {MODEL};Dyskinesia;{COVS};{FILE};data/{DATASET}_{SEX}_en.txt;/data/CARD/projects/dysk_prog/target2/result_en\"\n",
    "                print(line)\n",
    "                t=submitTerminal(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9c95b3-3848-420b-93a6-43c1784bdbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /data/CARD/projects/dysk_prog/target2\n",
    "tar -zcf target_en.tar.gz result_en/\n",
    "mv target_en.tar.gz ../target_en.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7390c71-5422-4d5a-8432-9d04bb07ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_lgs_outputs2(DATASET, SEX, MODEL):\n",
    "    d = pd.DataFrame()\n",
    "    for i in range(1,23):       \n",
    "        d1 = pd.read_csv(f'/data/CARD/projects/dysk_prog/logistic_en/{DATASET}.{SEX}.{MODEL}.chr{i}.Dyskinesia.glm.logistic', sep='\\t', low_memory=False)\n",
    "        d2 = pd.read_csv(f'/data/CARD/projects/dysk_prog/logistic_en/{DATASET}.{SEX}.{MODEL}.chr{i}.afreq', sep='\\t', low_memory=False)\n",
    "        if d1.shape[0] != d2.shape[0]:\n",
    "            print(f'ERROR for {DATASET}.{SEX}.{MODEL}.chr{i}')\n",
    "        else:\n",
    "            print(f'{DATASET}.{SEX}.{MODEL}.chr{i}')\n",
    "            d1['ALT_Frq'] = d2.ALT_FREQS\n",
    "            OR = pd.to_numeric(d1.OR, errors='coerce')\n",
    "            d1['OR'] = OR.where(d1.ALT==d1.A1, other=1/OR)\n",
    "            d1['Z_STAT'] = d1.Z_STAT.where(d1.ALT==d1.A1, other=-d1.Z_STAT)\n",
    "            L95 = pd.to_numeric(d1.L95, errors='coerce')\n",
    "            U95 = pd.to_numeric(d1.U95, errors='coerce')\n",
    "            LL = L95.where(d1.ALT==d1.A1, other=1/U95)\n",
    "            UL = U95.where(d1.ALT==d1.A1, other=1/L95)\n",
    "            d1['L95'] = LL\n",
    "            d1['U95'] = UL\n",
    "            d1 = d1.drop(columns=['A1'])\n",
    "            d = d.append(d1)\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d278861-cef8-4962-8096-7157fb46fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /data/CARD/projects/dysk_prog/RES_en\n",
    "for DATASET in ['SCOPA', 'CORIELL', 'PRECEPT']:\n",
    "    for SEX in ['ALL', 'MALE', 'FEMALE']:\n",
    "        for MODEL in ['ADJ', 'NOADJ']:\n",
    "            d = combine_lgs_outputs2(DATASET, SEX, MODEL)\n",
    "            d.to_csv(f'/data/CARD/projects/dysk_prog/RES_en/{DATASET}.{SEX}.{MODEL}.Dyskinesia.glm.logitstic.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a438f73-ab46-4a52-bb39-cfb8b31aaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /data/CARD/projects/dysk_prog\n",
    "tar -zcf RES_en.tar.gz RES_en/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d608cf3-c799-44c4-9f08-9e1fb34ed8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /data/CARD/projects/dysk_prog/logistic_en/SCOPA.ALL.ADJ.chr*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a746977-c253-46c6-9981-e4eae66534d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
